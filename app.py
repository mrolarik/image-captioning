import streamlit as st
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
import torch
import requests
from io import BytesIO

# ==== Load model and processor ====
@st.cache_resource
def load_model():
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return processor, model

processor, model = load_model()

# ==== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û ====
sample_images = {
    "‡∏™‡∏∏‡∏ô‡∏±‡∏Ç": "https://images.unsplash.com/photo-1601758123927-196d5f5fb692",
    "‡∏à‡∏±‡∏Å‡∏£‡∏¢‡∏≤‡∏ô": "https://images.unsplash.com/photo-1589571894960-20bbe2828f3b"
}

st.title("üñºÔ∏è Image Captioning App")
st.write("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á, ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î, ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡πâ‡∏≠‡∏ô URL ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì")

# ==== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û (‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô main area) ====
st.subheader("üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
cols = st.columns(len(sample_images))
selected_sample = None

for idx, (label, url) in enumerate(sample_images.items()):
    with cols[idx]:
        st.image(url, caption=label, use_column_width=True)
        if st.button(f"‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {label}", key=f"sample_{idx}"):
            selected_sample = url
            st.session_state['selected_sample_label'] = label

# ==== ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ ====
image = None

# ‚úÖ ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
if selected_sample:
    try:
        response = requests.get(selected_sample)
        image = Image.open(BytesIO(response.content)).convert("RGB")
        st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ({st.session_state.get('selected_sample_label', '')}) ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    except:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ")

# ‚úÖ ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
uploaded_file = st.file_uploader("üìÅ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì", type=["png", "jpg", "jpeg"])
if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‚úÖ ‡∏à‡∏≤‡∏Å URL
image_url_input = st.text_input("üîó ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡πâ‡∏≠‡∏ô URL ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ .jpg, .png, .jpeg)")
if image_url_input and not uploaded_file and not selected_sample:
    try:
        if image_url_input.lower().endswith((".jpg", ".jpeg", ".png")):
            response = requests.get(image_url_input)
            image = Image.open(BytesIO(response.content)).convert("RGB")
            st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å URL ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        else:
            st.warning("‚ö†Ô∏è URL ‡∏Ñ‡∏ß‡∏£‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ .jpg, .jpeg ‡∏´‡∏£‡∏∑‡∏≠ .png")
    except:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å URL ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")

# ==== ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ====
if image:
    st.image(image, caption="üì∏ ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", use_container_width=True)

    with st.spinner("üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û..."):
        inputs = processor(images=image, return_tensors="pt")
        out = model.generate(**inputs)
        caption = processor.decode(out[0], skip_special_tokens=True)

    st.success("üìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
    st.markdown(f"**{caption}**")
